"""
æ¨èç³»ç»ŸçœŸå®åœºæ™¯æµ‹è¯•

ä½¿ç”¨çœŸå®æ•°æ®åº“ä¸­çš„è®ºæ–‡æµ‹è¯•æ¨èåŠŸèƒ½
"""

import sys
import io

if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from apd.recommender import Recommender
from apd.db import get_connection, upsert_paper
from apd.utils import now_iso


def print_header(text):
    print("\n" + "=" * 70)
    print(f"  {text}")
    print("=" * 70)


def test_with_real_data():
    """æµ‹è¯•çœŸå®æ•°æ®åº“ä¸­çš„è®ºæ–‡"""
    print_header("åœºæ™¯1: ä½¿ç”¨çœŸå®è®ºæ–‡æ•°æ®æµ‹è¯•")

    # è·å–çœŸå®è®ºæ–‡
    with get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT paper_id, title, quality_score, filtered_out
            FROM papers
            WHERE week_id LIKE '%2026-05%'
            LIMIT 10
        """)
        real_papers = cursor.fetchall()

    print(f"\nğŸ“Š æ•°æ®åº“ä¸­çš„è®ºæ–‡çŠ¶æ€:")
    print(f"  æ€»è®ºæ–‡æ•°: {len(real_papers)}")

    filtered_count = sum(1 for p in real_papers if p['filtered_out'])
    print(f"  å·²è¿‡æ»¤: {filtered_count}")
    print(f"  å¯æ¨è: {len(real_papers) - filtered_count}")

    if filtered_count == len(real_papers):
        print(f"\nâš ï¸ æ‰€æœ‰è®ºæ–‡éƒ½è¢«è´¨é‡æ§åˆ¶ç³»ç»Ÿè¿‡æ»¤äº†")
        print(f"  åŸå› : è´¨é‡è¯„åˆ† < 60.0ï¼ˆé»˜è®¤é˜ˆå€¼ï¼‰")
        print(f"  è§£å†³æ–¹æ¡ˆ:")
        print(f"    1. é™ä½è´¨é‡é˜ˆå€¼: ä¿®æ”¹ .env ä¸­çš„ MIN_QUALITY_SCORE")
        print(f"    2. é‡æ–°è¯„åˆ†: ä½¿ç”¨æ›´å¥½çš„è´¨é‡è¯„ä¼°ç­–ç•¥")
        print(f"    3. æµ‹è¯•ç”¨è¢«è¿‡æ»¤è®ºæ–‡: ä¿®æ”¹æ¨èæŸ¥è¯¢æ¡ä»¶")


def test_create_high_quality_papers():
    """åˆ›å»ºä¸€äº›é«˜è´¨é‡è®ºæ–‡ç”¨äºæµ‹è¯•"""
    print_header("åœºæ™¯2: åˆ›å»ºé«˜è´¨é‡æµ‹è¯•è®ºæ–‡")

    week_id = "2026-05"

    test_papers = [
        {
            'paper_id': 'test_real_1',
            'title': 'Multimodal Large Language Models: A Survey',
            'summary': 'A comprehensive survey of multimodal large language models.',
            'quality_score': 92.0,
            'recency_score': 95.0,
            'citation_score': 88.0,
        },
        {
            'paper_id': 'test_real_2',
            'title': 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models',
            'summary': 'We explore how generating a chain of thought can improve reasoning.',
            'quality_score': 95.0,
            'recency_score': 90.0,
            'citation_score': 100.0,
        },
        {
            'paper_id': 'test_real_3',
            'title': 'LLaMA: Open and Efficient Foundation Language Models',
            'summary': 'We introduce LLaMA, a collection of foundation language models.',
            'quality_score': 90.0,
            'recency_score': 85.0,
            'citation_score': 95.0,
        },
        {
            'paper_id': 'test_real_4',
            'title': 'Diffusion Models Beat GANs on Image Synthesis',
            'summary': 'We show that diffusion models can achieve better image generation quality.',
            'quality_score': 88.0,
            'recency_score': 80.0,
            'citation_score': 90.0,
        },
        {
            'paper_id': 'test_real_5',
            'title': 'InstructGPT: Training language models to follow instructions',
            'summary': 'We fine-tune GPT-3 to follow instructions better.',
            'quality_score': 93.0,
            'recency_score': 88.0,
            'citation_score': 92.0,
        },
    ]

    for paper in test_papers:
        upsert_paper(
            paper_id=paper['paper_id'],
            week_id=week_id,
            title=paper['title'],
            summary=paper.get('summary'),
            quality_score=paper['quality_score'],
            recency_score=paper['recency_score'],
            citation_score=paper['citation_score'],
            filtered_out=0,  # ä¸è¿‡æ»¤
            content_type="PAPER"
        )

    print(f"\nâœ… åˆ›å»ºäº† {len(test_papers)} ç¯‡é«˜è´¨é‡æµ‹è¯•è®ºæ–‡")
    for i, paper in enumerate(test_papers, 1):
        print(f"  {i}. {paper['title'][:50]}... (è´¨é‡: {paper['quality_score']:.0f})")


def test_popular_recommendation():
    """æµ‹è¯•çƒ­é—¨æ¨è"""
    print_header("åœºæ™¯3: çƒ­é—¨æ¨èæµ‹è¯•")

    recommender = Recommender(user_id="test_real_user")
    results = recommender.recommend_popular(week_id="2026-05", limit=5)

    if results:
        print(f"\nâœ¨ æ‰¾åˆ° {len(results)} æ¡çƒ­é—¨æ¨è:")
        print(f"\n{'#':<3} {'è¯„åˆ†':<6} {'æ ‡é¢˜':<55}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            title = result.title[:52] + "..." if len(result.title) > 55 else result.title
            print(f"{i:<3} {result.score:<6.1f} {title}")
            if result.reasons:
                print(f"     ğŸ’¡ {' | '.join(result.reasons)}")
    else:
        print("\nâŒ æœªæ‰¾åˆ°æ¨èï¼ˆå¯èƒ½æ‰€æœ‰è®ºæ–‡éƒ½è¢«è¿‡æ»¤ï¼‰")


def test_user_interactions():
    """æµ‹è¯•ç”¨æˆ·äº¤äº’"""
    print_header("åœºæ™¯4: ç”¨æˆ·äº¤äº’æµ‹è¯•")

    user_id = "test_real_user"
    recommender = Recommender(user_id=user_id)

    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º
    interactions = [
        ('test_real_2', 'view', "æŸ¥çœ‹è®ºæ–‡"),
        ('test_real_2', 'favorite', "æ”¶è—è®ºæ–‡"),
        ('test_real_1', 'view', "æŸ¥çœ‹è®ºæ–‡"),
        ('test_real_3', 'view', "æŸ¥çœ‹è®ºæ–‡"),
        ('test_real_3', 'share', "åˆ†äº«è®ºæ–‡"),
    ]

    print(f"\nğŸ“Š æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º:")
    for paper_id, action, desc in interactions:
        recommender.track_interaction(paper_id, action)

        # è·å–è®ºæ–‡æ ‡é¢˜
        with get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT title FROM papers WHERE paper_id = ?", (paper_id,))
            row = cursor.fetchone()
            title = row['title'][:40] + "..." if row and len(row['title']) > 40 else (row['title'] if row else paper_id)

        action_icons = {'view': 'ğŸ‘€', 'favorite': 'â­', 'share': 'ğŸ“¤'}
        print(f"  {action_icons.get(action, 'â€¢')} {desc}: {title}")

    # ç»Ÿè®¡äº¤äº’
    with get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT
                action_type,
                COUNT(*) as cnt,
                SUM(interaction_score) as total_score
            FROM user_interactions
            WHERE user_id = ?
            GROUP BY action_type
        """, (user_id,))
        stats = cursor.fetchall()

    print(f"\nğŸ“ˆ äº¤äº’ç»Ÿè®¡:")
    for row in stats:
        print(f"  {row['action_type']}: {row['cnt']} æ¬¡ (æ€»åˆ†: {row['total_score']:.1f})")


def test_similar_recommendation():
    """æµ‹è¯•ç›¸ä¼¼æ¨è"""
    print_header("åœºæ™¯5: ç›¸ä¼¼è®ºæ–‡æ¨èæµ‹è¯•")

    recommender = Recommender(user_id="test_real_user")

    base_paper = "test_real_2"
    print(f"\nğŸ” æŸ¥æ‰¾ä¸è®ºæ–‡ {base_paper} ç›¸ä¼¼çš„è®ºæ–‡...")

    # è·å–åŸºå‡†è®ºæ–‡æ ‡é¢˜
    with get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT title FROM papers WHERE paper_id = ?", (base_paper,))
        row = cursor.fetchone()
        if row:
            print(f"   åŸºå‡†è®ºæ–‡: {row['title']}")

    results = recommender.recommend_similar(
        paper_id=base_paper,
        limit=3,
        min_similarity=0.0
    )

    if results:
        print(f"\nâœ¨ æ‰¾åˆ° {len(results)} æ¡ç›¸ä¼¼æ¨è:")
        print(f"\n{'#':<3} {'ç›¸ä¼¼åº¦':<8} {'æ ‡é¢˜':<55}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            title = result.title[:52] + "..." if len(result.title) > 55 else result.title
            print(f"{i:<3} {result.score:<8.2f} {title}")
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°ç›¸ä¼¼è®ºæ–‡")
        print(f"   æç¤º: å®‰è£… sentence-transformers å¯å¯ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦")


def test_hybrid_recommendation():
    """æµ‹è¯•æ··åˆæ¨è"""
    print_header("åœºæ™¯6: æ··åˆæ¨èæµ‹è¯•")

    # æ–°ç”¨æˆ·
    print(f"\nğŸ†• æ–°ç”¨æˆ· (æ— äº¤äº’è®°å½•):")
    new_user = Recommender(user_id="new_test_user")
    results = new_user.recommend_hybrid(week_id="2026-05", limit=3)

    if results:
        print(f"   ç­–ç•¥: {results[0].strategy}")
        for i, result in enumerate(results, 1):
            title = result.title[:50] + "..." if len(result.title) > 50 else result.title
            print(f"   {i}. {title}")

    # æ´»è·ƒç”¨æˆ·
    print(f"\nğŸ‘¤ æ´»è·ƒç”¨æˆ· (æœ‰äº¤äº’è®°å½•):")
    active_user = Recommender(user_id="test_real_user")
    results = active_user.recommend_hybrid(week_id="2026-05", limit=3)

    if results:
        strategies = set(r.strategy for r in results)
        print(f"   ç­–ç•¥: {', '.join(strategies)}")
        for i, result in enumerate(results, 1):
            title = result.title[:50] + "..." if len(result.title) > 50 else result.title
            print(f"   {i}. {title}")


def test_recommendation_stats():
    """æµ‹è¯•æ¨èç»Ÿè®¡"""
    print_header("åœºæ™¯7: æ¨èç³»ç»Ÿç»Ÿè®¡")

    with get_connection() as conn:
        cursor = conn.cursor()

        # äº¤äº’ç»Ÿè®¡
        cursor.execute("""
            SELECT COUNT(*) as cnt, COUNT(DISTINCT user_id) as users
            FROM user_interactions
            WHERE user_id LIKE 'test_real%' OR user_id = 'new_test_user'
        """)
        interaction_stats = cursor.fetchone()

        # æ¨èç»Ÿè®¡
        cursor.execute("""
            SELECT COUNT(*) as cnt, COUNT(DISTINCT strategy) as strategies
            FROM recommendations
            WHERE user_id LIKE 'test_real%' OR user_id = 'new_test_user'
        """)
        rec_stats = cursor.fetchone()

        # çƒ­é—¨è®ºæ–‡
        cursor.execute("""
            SELECT p.paper_id, p.title, COUNT(*) as interactions
            FROM user_interactions ui
            JOIN papers p ON ui.paper_id = p.paper_id
            WHERE ui.user_id LIKE 'test_real%'
            GROUP BY p.paper_id
            ORDER BY interactions DESC
            LIMIT 3
        """)
        hot_papers = cursor.fetchall()

    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  ç”¨æˆ·æ•°: {interaction_stats['users']}")
    print(f"  äº¤äº’æ¬¡æ•°: {interaction_stats['cnt']}")
    print(f"  æ¨èæ¬¡æ•°: {rec_stats['cnt']}")

    if hot_papers:
        print(f"\nğŸ”¥ æœ€çƒ­é—¨è®ºæ–‡:")
        for i, row in enumerate(hot_papers, 1):
            title = row['title'][:50] + "..." if len(row['title']) > 50 else row['title']
            print(f"  {i}. {title} ({row['interactions']} æ¬¡äº¤äº’)")


def cleanup():
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    print_header("æ¸…ç†æµ‹è¯•æ•°æ®")

    with get_connection() as conn:
        cursor = conn.cursor()

        cursor.execute("DELETE FROM papers WHERE paper_id LIKE 'test_real_%'")
        papers_deleted = cursor.rowcount

        cursor.execute("DELETE FROM user_interactions WHERE user_id LIKE 'test_real%' OR user_id = 'new_test_user'")
        interactions_deleted = cursor.rowcount

        cursor.execute("DELETE FROM recommendations WHERE user_id LIKE 'test_real%' OR user_id = 'new_test_user'")
        recommendations_deleted = cursor.rowcount

        conn.commit()

    print(f"\nâœ… æ¸…ç†å®Œæˆ:")
    print(f"  åˆ é™¤è®ºæ–‡: {papers_deleted}")
    print(f"  åˆ é™¤äº¤äº’: {interactions_deleted}")
    print(f"  åˆ é™¤æ¨è: {recommendations_deleted}")


def main():
    print("\n" + "=" * 70)
    print("  æ¨èç³»ç»ŸçœŸå®åœºæ™¯æµ‹è¯•")
    print("=" * 70)

    try:
        # æµ‹è¯•çœŸå®æ•°æ®
        test_with_real_data()

        # åˆ›å»ºé«˜è´¨é‡æµ‹è¯•æ•°æ®
        test_create_high_quality_papers()

        # æµ‹è¯•å„ç§æ¨èç­–ç•¥
        test_popular_recommendation()
        test_user_interactions()
        test_similar_recommendation()
        test_hybrid_recommendation()
        test_recommendation_stats()

    finally:
        # æ¸…ç†
        cleanup()

    print("\n" + "=" * 70)
    print("  æµ‹è¯•å®Œæˆ!")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()
