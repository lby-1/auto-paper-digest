"""
æ¨èç³»ç»Ÿæ¼”ç¤ºè„šæœ¬

å±•ç¤ºæ¨èç³»ç»Ÿçš„å„ç§åŠŸèƒ½
"""

import sys
import io

# Fix encoding for Windows
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from apd.recommender import Recommender
from apd.db import get_connection, upsert_paper, init_db
from apd.utils import now_iso


def print_header(text):
    print("\n" + "=" * 70)
    print(f"  {text}")
    print("=" * 70)


def setup_demo_data():
    """è®¾ç½®æ¼”ç¤ºæ•°æ®"""
    week_id = "2026-05"

    # åˆ›å»ºæ›´ä¸°å¯Œçš„æµ‹è¯•æ•°æ®
    papers = [
        {
            'paper_id': 'demo_paper_1',
            'title': 'Attention Is All You Need',
            'summary': 'We propose the Transformer, a new simple network architecture based solely on attention mechanisms.',
            'quality_score': 95.0,
            'recency_score': 85.0,
            'citation_score': 100.0,
        },
        {
            'paper_id': 'demo_paper_2',
            'title': 'BERT: Pre-training of Deep Bidirectional Transformers',
            'summary': 'We introduce BERT, which stands for Bidirectional Encoder Representations from Transformers.',
            'quality_score': 92.0,
            'recency_score': 80.0,
            'citation_score': 95.0,
        },
        {
            'paper_id': 'demo_paper_3',
            'title': 'GPT-3: Language Models are Few-Shot Learners',
            'summary': 'We show that scaling up language models greatly improves task-agnostic, few-shot performance.',
            'quality_score': 90.0,
            'recency_score': 90.0,
            'citation_score': 90.0,
        },
        {
            'paper_id': 'demo_paper_4',
            'title': 'ResNet: Deep Residual Learning for Image Recognition',
            'summary': 'We present a residual learning framework to ease the training of networks that are substantially deeper.',
            'quality_score': 88.0,
            'recency_score': 70.0,
            'citation_score': 100.0,
        },
        {
            'paper_id': 'demo_paper_5',
            'title': 'Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context',
            'summary': 'We propose Transformer-XL, a Transformer architecture that learns dependency beyond a fixed length.',
            'quality_score': 85.0,
            'recency_score': 75.0,
            'citation_score': 80.0,
        },
        {
            'paper_id': 'demo_paper_6',
            'title': 'EfficientNet: Rethinking Model Scaling for CNNs',
            'summary': 'We systematically study model scaling and propose a new scaling method called compound scaling.',
            'quality_score': 82.0,
            'recency_score': 75.0,
            'citation_score': 85.0,
        },
        {
            'paper_id': 'demo_paper_7',
            'title': 'CLIP: Learning Transferable Visual Models From Natural Language Supervision',
            'summary': 'We demonstrate that the simple pre-training task of predicting which caption goes with which image.',
            'quality_score': 88.0,
            'recency_score': 85.0,
            'citation_score': 88.0,
        },
        {
            'paper_id': 'demo_paper_8',
            'title': 'AlphaFold: Improved protein structure prediction',
            'summary': 'AlphaFold produces protein structure predictions that are accurate enough for practical use.',
            'quality_score': 98.0,
            'recency_score': 80.0,
            'citation_score': 95.0,
        },
    ]

    for paper in papers:
        upsert_paper(
            paper_id=paper['paper_id'],
            week_id=week_id,
            title=paper['title'],
            summary=paper.get('summary'),
            quality_score=paper['quality_score'],
            recency_score=paper['recency_score'],
            citation_score=paper['citation_score'],
            filtered_out=0,
            content_type="PAPER"
        )

    print(f"âœ“ åˆ›å»ºäº† {len(papers)} ç¯‡æ¼”ç¤ºè®ºæ–‡")


def demo_popular_recommendation():
    """æ¼”ç¤º1: çƒ­é—¨æ¨è"""
    print_header("Demo 1: çƒ­é—¨æ¨è")

    recommender = Recommender(user_id="demo_user")
    results = recommender.recommend_popular(limit=5)

    print(f"\nğŸ“ˆ åŸºäºè´¨é‡è¯„åˆ†ã€æ—¶æ•ˆæ€§å’Œå¼•ç”¨æ•°çš„çƒ­é—¨æ¨è:")
    print(f"\n{'#':<3} {'è¯„åˆ†':<6} {'æ ‡é¢˜':<50}")
    print("-" * 70)

    for i, result in enumerate(results, 1):
        title = result.title[:47] + "..." if len(result.title) > 50 else result.title
        print(f"{i:<3} {result.score:<6.2f} {title}")
        if result.reasons:
            print(f"     ğŸ’¡ {' | '.join(result.reasons)}")


def demo_similar_recommendation():
    """æ¼”ç¤º2: ç›¸ä¼¼æ¨è"""
    print_header("Demo 2: ç›¸ä¼¼è®ºæ–‡æ¨è")

    base_paper_title = "Attention Is All You Need"
    print(f"\nğŸ” å¯»æ‰¾ä¸ã€Š{base_paper_title}ã€‹ç›¸ä¼¼çš„è®ºæ–‡:\n")

    recommender = Recommender(user_id="demo_user")
    try:
        results = recommender.recommend_similar(
            paper_id="demo_paper_1",
            limit=3,
            min_similarity=0.0  # é™ä½é˜ˆå€¼ä»¥ä¾¿æ¼”ç¤º
        )

        if results:
            print(f"{'#':<3} {'ç›¸ä¼¼åº¦':<8} {'æ ‡é¢˜':<50}")
            print("-" * 70)

            for i, result in enumerate(results, 1):
                title = result.title[:47] + "..." if len(result.title) > 50 else result.title
                print(f"{i:<3} {result.score:<8.2f} {title}")
                if result.reasons:
                    print(f"     ğŸ’¡ {' | '.join(result.reasons)}")
        else:
            print("âš  æœªæ‰¾åˆ°ç›¸ä¼¼è®ºæ–‡ï¼ˆå¯èƒ½æ˜¯å› ä¸ºç¼ºå°‘ sentence-transformers åº“ï¼‰")
            print("  å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install sentence-transformers")
    except Exception as e:
        print(f"âš  ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
        print("  æç¤º: å®‰è£… sentence-transformers ä»¥å¯ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦åŠŸèƒ½")


def demo_user_interactions():
    """æ¼”ç¤º3: ç”¨æˆ·äº¤äº’è¿½è¸ª"""
    print_header("Demo 3: ç”¨æˆ·äº¤äº’è¿½è¸ª")

    recommender = Recommender(user_id="alice")

    print("\nğŸ“Š æ¨¡æ‹Ÿç”¨æˆ· Alice çš„è¡Œä¸º:\n")

    # Alice æŸ¥çœ‹äº†å‡ ç¯‡è®ºæ–‡
    papers_viewed = [
        ("demo_paper_1", "Attention Is All You Need"),
        ("demo_paper_2", "BERT: Pre-training of Deep Bidirectional Transformers"),
        ("demo_paper_3", "GPT-3: Language Models are Few-Shot Learners"),
    ]

    for paper_id, title in papers_viewed:
        recommender.track_interaction(paper_id, "view")
        print(f"  ğŸ‘€ æŸ¥çœ‹: {title[:50]}...")

    # Alice æ”¶è—äº†ä¸€äº›è®ºæ–‡
    papers_favorited = [
        ("demo_paper_1", "Attention Is All You Need"),
        ("demo_paper_3", "GPT-3: Language Models are Few-Shot Learners"),
    ]

    print()
    for paper_id, title in papers_favorited:
        recommender.track_interaction(paper_id, "favorite")
        print(f"  â­ æ”¶è—: {title[:50]}...")

    # Alice åˆ†äº«äº†ä¸€ç¯‡è®ºæ–‡
    print()
    recommender.track_interaction("demo_paper_3", "share")
    print(f"  ğŸ“¤ åˆ†äº«: GPT-3: Language Models are Few-Shot Learners")

    # ç»Ÿè®¡äº¤äº’æ•°æ®
    with get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT action_type, COUNT(*) as cnt, SUM(interaction_score) as total_score
            FROM user_interactions
            WHERE user_id = 'alice'
            GROUP BY action_type
        """, ())
        stats = cursor.fetchall()

    print("\nğŸ“ˆ Alice çš„äº¤äº’ç»Ÿè®¡:")
    for row in stats:
        print(f"  - {row['action_type']}: {row['cnt']} æ¬¡ (æ€»åˆ†: {row['total_score']:.1f})")


def demo_collaborative_filtering():
    """æ¼”ç¤º4: ååŒè¿‡æ»¤"""
    print_header("Demo 4: ååŒè¿‡æ»¤æ¨è")

    # åˆ›å»ºå¦ä¸€ä¸ªç”¨æˆ· Bobï¼Œä»–å’Œ Alice æœ‰ç›¸ä¼¼çš„å…´è¶£
    bob = Recommender(user_id="bob")
    bob.track_interaction("demo_paper_1", "favorite")  # å’Œ Alice å…±åŒå–œæ¬¢
    bob.track_interaction("demo_paper_3", "favorite")  # å’Œ Alice å…±åŒå–œæ¬¢
    bob.track_interaction("demo_paper_5", "favorite")  # Bob å–œæ¬¢ä½† Alice è¿˜æ²¡çœ‹è¿‡

    print("\nğŸ‘¥ ç”¨æˆ· Bob ä¹Ÿå–œæ¬¢:")
    print("  â­ Attention Is All You Need")
    print("  â­ GPT-3: Language Models are Few-Shot Learners")
    print("  â­ Transformer-XL (Alice è¿˜æ²¡çœ‹è¿‡)")

    print("\nğŸ¯ ä¸º Alice ç”ŸæˆååŒè¿‡æ»¤æ¨è:")

    alice = Recommender(user_id="alice")
    results = alice.recommend_collaborative(limit=3)

    if results:
        print(f"\n{'#':<3} {'è¯„åˆ†':<6} {'æ ‡é¢˜':<50}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            title = result.title[:47] + "..." if len(result.title) > 50 else result.title
            print(f"{i:<3} {result.score:<6.2f} {title}")
            if result.reasons:
                print(f"     ğŸ’¡ {' | '.join(result.reasons)}")
    else:
        print("  âš  æš‚æ— ååŒè¿‡æ»¤æ¨èï¼ˆéœ€è¦æ›´å¤šç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼‰")


def demo_hybrid_recommendation():
    """æ¼”ç¤º5: æ··åˆæ¨è"""
    print_header("Demo 5: æ··åˆæ¨èç­–ç•¥")

    print("\nğŸ†• æ–°ç”¨æˆ· Charlieï¼ˆæ— å†å²è®°å½•ï¼‰:")
    charlie = Recommender(user_id="charlie")
    results = charlie.recommend_hybrid(limit=3)

    if results:
        print(f"\nç­–ç•¥: çƒ­é—¨æ¨èï¼ˆæ–°ç”¨æˆ·ï¼‰")
        print(f"{'#':<3} {'è¯„åˆ†':<6} {'æ ‡é¢˜':<50}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            title = result.title[:47] + "..." if len(result.title) > 50 else result.title
            print(f"{i:<3} {result.score:<6.2f} {title}")

    print("\n\nğŸ‘¤ æ´»è·ƒç”¨æˆ· Aliceï¼ˆæœ‰ä¸°å¯Œå†å²è®°å½•ï¼‰:")
    alice = Recommender(user_id="alice")
    results = alice.recommend_hybrid(limit=3)

    if results:
        strategies = set(r.strategy for r in results)
        print(f"\nç­–ç•¥: {', '.join(strategies)} (æ´»è·ƒç”¨æˆ·)")
        print(f"{'#':<3} {'è¯„åˆ†':<6} {'ç­–ç•¥':<15} {'æ ‡é¢˜':<40}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            title = result.title[:37] + "..." if len(result.title) > 40 else result.title
            print(f"{i:<3} {result.score:<6.2f} {result.strategy:<15} {title}")


def demo_statistics():
    """æ¼”ç¤º6: æ¨èç³»ç»Ÿç»Ÿè®¡"""
    print_header("Demo 6: æ¨èç³»ç»Ÿç»Ÿè®¡")

    with get_connection() as conn:
        cursor = conn.cursor()

        # æ€»äº¤äº’æ•°
        cursor.execute("SELECT COUNT(*) as cnt FROM user_interactions")
        total_interactions = cursor.fetchone()['cnt']

        # ç‹¬ç«‹ç”¨æˆ·æ•°
        cursor.execute("SELECT COUNT(DISTINCT user_id) as cnt FROM user_interactions")
        unique_users = cursor.fetchone()['cnt']

        # æ€»æ¨èæ•°
        cursor.execute("SELECT COUNT(*) as cnt FROM recommendations")
        total_recommendations = cursor.fetchone()['cnt']

        # æ¨èç­–ç•¥åˆ†å¸ƒ
        cursor.execute("""
            SELECT strategy, COUNT(*) as cnt
            FROM recommendations
            GROUP BY strategy
        """)
        strategy_stats = cursor.fetchall()

        # æœ€çƒ­é—¨çš„è®ºæ–‡
        cursor.execute("""
            SELECT p.paper_id, p.title, COUNT(*) as interaction_count
            FROM user_interactions ui
            JOIN papers p ON ui.paper_id = p.paper_id
            GROUP BY p.paper_id
            ORDER BY interaction_count DESC
            LIMIT 3
        """)
        hot_papers = cursor.fetchall()

    print(f"\nğŸ“Š æ¨èç³»ç»Ÿæ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»äº¤äº’æ•°: {total_interactions}")
    print(f"  ç‹¬ç«‹ç”¨æˆ·: {unique_users}")
    print(f"  æ€»æ¨èæ•°: {total_recommendations}")

    if strategy_stats:
        print(f"\nğŸ“ˆ æ¨èç­–ç•¥åˆ†å¸ƒ:")
        for row in strategy_stats:
            print(f"  - {row['strategy']}: {row['cnt']} æ¬¡")

    if hot_papers:
        print(f"\nğŸ”¥ æœ€çƒ­é—¨è®ºæ–‡:")
        for i, row in enumerate(hot_papers, 1):
            title = row['title'][:50] + "..." if len(row['title']) > 50 else row['title']
            print(f"  {i}. {title} ({row['interaction_count']} æ¬¡äº¤äº’)")


def cleanup_demo_data():
    """æ¸…ç†æ¼”ç¤ºæ•°æ®"""
    print_header("æ¸…ç†æ¼”ç¤ºæ•°æ®")

    with get_connection() as conn:
        cursor = conn.cursor()

        cursor.execute("DELETE FROM papers WHERE paper_id LIKE 'demo_paper_%'")
        papers_deleted = cursor.rowcount

        cursor.execute("DELETE FROM user_interactions WHERE user_id IN ('demo_user', 'alice', 'bob', 'charlie')")
        interactions_deleted = cursor.rowcount

        cursor.execute("DELETE FROM recommendations WHERE user_id IN ('demo_user', 'alice', 'bob', 'charlie')")
        recommendations_deleted = cursor.rowcount

        conn.commit()

    print(f"\nâœ… å·²åˆ é™¤:")
    print(f"  - {papers_deleted} ç¯‡æ¼”ç¤ºè®ºæ–‡")
    print(f"  - {interactions_deleted} æ¡äº¤äº’è®°å½•")
    print(f"  - {recommendations_deleted} æ¡æ¨èè®°å½•")


def main():
    print("\n" + "=" * 70)
    print("  æ™ºèƒ½æ¨èç³»ç»Ÿæ¼”ç¤º")
    print("=" * 70)

    # ç¡®ä¿æ•°æ®åº“å·²åˆå§‹åŒ–
    init_db()

    try:
        # è®¾ç½®æ¼”ç¤ºæ•°æ®
        setup_demo_data()

        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        demo_popular_recommendation()
        demo_similar_recommendation()
        demo_user_interactions()
        demo_collaborative_filtering()
        demo_hybrid_recommendation()
        demo_statistics()

    finally:
        # æ¸…ç†æ¼”ç¤ºæ•°æ®
        cleanup_demo_data()

    print("\n" + "=" * 70)
    print("  æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()
